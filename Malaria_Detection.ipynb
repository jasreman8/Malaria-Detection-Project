{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1BMt4ja28FM"
   },
   "source": [
    "# **Malaria Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCiPVBNbA0Wh"
   },
   "source": [
    "## <b>Problem Definition</b>\n",
    "**The context:** Malaria is a life-threatening disease caused by Plasmodium parasites, transmitted through bites of infected female Anopheles mosquitoes. It affects nearly half of the global population, with over 229 million cases and 400,000 deaths reported in 2019—67% of which were children under five. The parasite can remain in the body for over a year without symptoms, making early detection critical. Traditional diagnosis relies on manual inspection of red blood cells (RBCs), which is labor-intensive, time-consuming, and subject to human error. Automating this process using Machine Learning (ML) and Deep Learning (DL) techniques has shown promise in improving diagnostic accuracy and efficiency. This project aims to develop an AI-based solution for accurate and early malaria detection.<br>\n",
    "\n",
    "\n",
    "**The objectives:** The goal is to build an efficient computer vision model that can automatically detect malaria by analyzing images of red blood cells. The model should classify each cell image as either parasitized (infected with malaria) or uninfected, enabling fast and accurate diagnosis.<br>\n",
    "\n",
    "\n",
    "**The key questions:** \n",
    " - Can we accurately detect malaria-infected red blood cells using image data?\n",
    " - What deep learning architecture yields the best performance for malaria classification?\n",
    " - How can we optimize the model for both accuracy and computational efficiency?\n",
    " - What is the minimum amount of data or preprocessing required to achieve high accuracy?\n",
    " - How generalizable is the model across different datasets or imaging conditions?<br>\n",
    "\n",
    "\n",
    "**The problem formulation:** This project aims to solve a binary image classification problem using data science and deep learning techniques. Specifically, the task is to develop a computer vision model that can:\n",
    " - Take as input an image of a red blood cell from a blood smear,\n",
    " - Automatically analyze the visual features,\n",
    " - And classify the image as either parasitized (malaria-infected) or uninfected.\n",
    "\n",
    "The broader objective is to support rapid, accurate, and scalable malaria diagnosis in clinical and resource-constrained settings, thereby reducing dependence on manual microscopy and enabling timely treatment\n",
    "\n",
    "## <b>Data Description </b>\n",
    "\n",
    "There are a total of 24,958 train and 2,600 test images (colored) that we have taken from microscopic images. These images are of the following categories:<br>\n",
    "\n",
    "\n",
    "**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria<br>\n",
    "**Uninfected:** The uninfected cells are free of the Plasmodium parasites<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGsTRO4XBWKn"
   },
   "source": [
    "## <b>Important Notes</b>\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "### <b>Loading libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iixNDZWs1ZPL"
   },
   "outputs": [],
   "source": [
    "# Importing libraries required to load the data\n",
    "import zipfile\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Remove the limit from the number of displayed columns and rows. It helps to see the entire dataframe while printing it\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### <b>Let us load the data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_syvBdMlDTsr"
   },
   "source": [
    "**Note:** \n",
    "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
    "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ufMU62DICjLV"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the data file from the Google drive\n",
    "path = 'cell_images.zip'\n",
    "\n",
    "# The data is provided as a zip file so we need to extract the files from the zip file\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW3fDq7gF4Hw"
   },
   "source": [
    "The extracted folder has different folders for train and test data which further contains the different sizes of images for parasitized and uninfected cells within the respective folder name. \n",
    "\n",
    "The size of all images must be the same and should be converted to 4D arrays so that they can be used as an input for the convolutional neural network. Also, we need to create the labels for both types of images to be able to train and test the model. \n",
    "\n",
    "Let's do the same for the training data first and then we will use the same code for the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SjK02uF1DXdW"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the extracted \"train\" folder \n",
    "train_dir = 'cell_images/train'\n",
    "\n",
    "# Size of image so that each image has the same size\n",
    "SIZE = 64\n",
    "\n",
    "# Empty list to store the training images after they are converted to NumPy arrays\n",
    "train_images = []\n",
    "\n",
    "# Empty list to store the training labels (0 - uninfected, 1 - parasitized)\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2JNY4tSvDXgn"
   },
   "outputs": [],
   "source": [
    "# We will run the same code for \"parasitized\" as well as \"uninfected\" folders within the \"train\" folder\n",
    "for folder_name in ['/parasitized/', '/uninfected/']:\n",
    "    \n",
    "    # Path of the folder\n",
    "    images_path = os.listdir(train_dir + folder_name)\n",
    "\n",
    "    for i, image_name in enumerate(images_path):\n",
    "    \n",
    "        try:\n",
    "    \n",
    "            # Opening each image using the path of that image\n",
    "            image = Image.open(train_dir + folder_name + image_name)\n",
    "\n",
    "            # Resizing each image to (64, 64)\n",
    "            image = image.resize((SIZE, SIZE))\n",
    "\n",
    "            # Converting images to arrays and appending that array to the empty list defined above\n",
    "            train_images.append(np.array(image))\n",
    "\n",
    "            # Creating labels for parasitized and uninfected images\n",
    "            if folder_name == '/parasitized/':\n",
    "            \n",
    "                train_labels.append(1)\n",
    "           \n",
    "            else:\n",
    "           \n",
    "                train_labels.append(0)\n",
    "        \n",
    "        except Exception:\n",
    "       \n",
    "            pass       \n",
    "\n",
    "# Converting lists to arrays\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DfwXIsK_DXiv"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the extracted \"test\" folder \n",
    "test_dir = 'cell_images/test'\n",
    "\n",
    "# Size of image so that each image has the same size (it must be same as the train image size)\n",
    "SIZE = 64\n",
    "\n",
    "# Empty list to store the testing images after they are converted to NumPy arrays\n",
    "test_images = []\n",
    "\n",
    "# Empty list to store the testing labels (0 - uninfected, 1 - parasitized)\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "My6pm3AFDXk9"
   },
   "outputs": [],
   "source": [
    "# We will run the same code for \"parasitized\" as well as \"uninfected\" folders within the \"test\" folder\n",
    "for folder_name in ['/parasitized/', '/uninfected/']:\n",
    "    \n",
    "    # Path of the folder\n",
    "    images_path = os.listdir(test_dir + folder_name)\n",
    "\n",
    "    for i, image_name in enumerate(images_path):\n",
    "\n",
    "        try:\n",
    "            # Opening each image using the path of that image\n",
    "            image = Image.open(test_dir + folder_name + image_name)\n",
    "            \n",
    "            # Resizing each image to (64, 64)\n",
    "            image = image.resize((SIZE, SIZE))\n",
    "            \n",
    "            # Converting images to arrays and appending that array to the empty list defined above\n",
    "            test_images.append(np.array(image))\n",
    "            \n",
    "            # Creating labels for parasitized and uninfected images\n",
    "            if folder_name == '/parasitized/':\n",
    "\n",
    "                test_labels.append(1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_labels.append(0)\n",
    "\n",
    "        except Exception:\n",
    "\n",
    "            pass       \n",
    "\n",
    "# Converting lists to arrays\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_rxFT9iH7pR"
   },
   "source": [
    "### <b> Checking the shape of train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LA8HJmQp1hU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (24958, 64, 64, 3)\n",
      "Shape of testing images: (2600, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training images:\", train_images.shape)\n",
    "print(\"Shape of testing images:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3AiiutGIEoy"
   },
   "source": [
    "### <b> Checking the shape of train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UJ_uvmT61rvx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training labels: (24958,)\n",
      "Shape of testing labels: (2600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training labels:\", train_labels.shape)\n",
    "print(\"Shape of testing labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3gtgoubINVX"
   },
   "source": [
    "#### <b> 📊 Observations:\n",
    "\n",
    "🔹 Training Data\n",
    " - train_images.shape = (24,958, 64, 64, 3)\n",
    " - We have 24,958 RGB images, each of size 64x64 pixels.\n",
    "\n",
    "train_labels.shape = (24,958,)\n",
    " -  There are 24,958 corresponding labels, meaning every image has one label.\n",
    "\n",
    "🔹 Testing Data\n",
    " - test_images.shape = (2,600, 64, 64, 3)\n",
    " - The test set contains 2,600 RGB images, also of size 64x64.\n",
    "\n",
    " - test_labels.shape = (2,600,)\n",
    " -  You have 2,600 labels—again, a 1-to-1 match with the test images.\n",
    "\n",
    "<b> 📈 Insights:\n",
    "\n",
    "✅ Data is well-aligned\n",
    "\n",
    "The number of images matches the number of labels in both training and testing sets, so our dataset is properly structured for supervised learning.\n",
    "\n",
    "📦 We're using RGB images\n",
    "\n",
    "The 3 in the shape (last dimension) confirms all our images are in color (RGB), not grayscale.\n",
    "\n",
    "🧪 We’re using a ~90/10 split\n",
    "\n",
    "Total images = 24,958 (train) + 2,600 (test) = 27,558\n",
    "\n",
    "Train set = ~90.6%\n",
    "\n",
    "Test set = ~9.4%\n",
    "\n",
    "✅ This is a reasonable and commonly used split for image classification tasks.\n",
    "\n",
    "📐 Uniform Image Dimensions\n",
    "\n",
    "All images are consistently sized to 64x64, which ensures efficient training and compatibility with CNN models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFUMkif7IjlO"
   },
   "source": [
    "### <b>Check the minimum and maximum range of pixel values for train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_gJbhCbMIswX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images pixel range: 0 to 255\n",
      "Test images pixel range: 0 to 255\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images pixel range:\", train_images.min(), \"to\", train_images.max())\n",
    "print(\"Test images pixel range:\", test_images.min(), \"to\", test_images.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T8WWuSpI6Ih"
   },
   "source": [
    "#### <b> Observations:\n",
    " - The pixel values for both train and test images range from 0 to 255.\n",
    " - This indicates that the images are in standard 8-bit RGB format, where each channel (Red, Green, Blue) can take values from 0 (darkest) to 255 (brightest).\n",
    " - The pixel range is consistent across both datasets, which is important for model training and evaluation.\n",
    "\n",
    " <b> Insights:\n",
    "  - Since the pixel values are not normalized, it is recommended to scale them to the [0,1] range before feeding them into a neural network. This helps the model train more efficiently and can improve convergence.\n",
    "  - The consistency in pixel range between train and test sets ensures that the model will not encounter unexpected data distributions during interference.\n",
    "  - No outliers or corrupted images are present in termins of pixel intensity, which means the data quality is good for image classification tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywUFcLSCPIqz"
   },
   "source": [
    "### <b> Count the number of values in both uninfected and parasitized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xcEb9liBPRlu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts:\n",
      "1    12582\n",
      "0    12376\n",
      "Name: count, dtype: int64\n",
      "******************************\n",
      "Test label counts:\n",
      "1    1300\n",
      "0    1300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training label counts:\")\n",
    "print(pd.Series(train_labels).value_counts())\n",
    "print(30*\"*\")\n",
    "print(\"Test label counts:\")\n",
    "print(pd.Series(test_labels).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U71xb2XJe0t"
   },
   "source": [
    "### <b>Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqzvvNS9IvsP"
   },
   "outputs": [],
   "source": [
    "# Try to normalize the train and test images by dividing it by 255 and convert them to float32 using astype function\n",
    "train_images = (___________).astype('float32')\n",
    "\n",
    "test_images = (______________).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAT1eVTrKiDy"
   },
   "source": [
    "####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG4meNZBKZ5r"
   },
   "source": [
    "###<b> Plot to check if the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N4qohCFIvvI"
   },
   "outputs": [],
   "source": [
    "# You are free to use bar plot or pie-plot or count plot, etc. to plot the labels of train and test data and check if they are balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGfRJaffLI-C"
   },
   "source": [
    "####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16-Er2edMzsD"
   },
   "source": [
    "### <b>Data Exploration</b>\n",
    "Let's visualize the images from the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjhRVQ3-2Pa5"
   },
   "outputs": [],
   "source": [
    "# This code will help you in visualizing both the parasitized and uninfected images\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.figure(1, figsize = (16 , 16))\n",
    "\n",
    "for n in range(1, 17):\n",
    "\n",
    "    plt.subplot(4, 4, n)\n",
    "\n",
    "    index = int(np.random.randint(0, train_images.shape[0], 1))\n",
    "\n",
    "    if train_labels[index] == 1: \n",
    "\n",
    "        plt.title('parasitized')\n",
    "\n",
    "    else:\n",
    "        plt.title('uninfected')\n",
    "\n",
    "    plt.imshow(train_images[index])\n",
    "\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnyS_9IcCZLp"
   },
   "source": [
    "####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4oo5HrTDha"
   },
   "source": [
    "###<b> Similarly visualize the images with subplot(6, 6) and figsize = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKmncZ-fTAdD"
   },
   "outputs": [],
   "source": [
    "# Hint: Have a keen look into the number of iterations that the for loop should iterate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTG8UaNNNNso"
   },
   "source": [
    "####<b>Observations and insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifjZ2G0YN20r"
   },
   "source": [
    "###<b> Plotting the mean images for parasitized and uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN9X0620Iv1a"
   },
   "outputs": [],
   "source": [
    "# Function to find the mean\n",
    "def find_mean_img(full_mat, title):\n",
    "\n",
    "    # Calculate the average\n",
    "    mean_img = np.mean(full_mat, axis = 0)[0]\n",
    "\n",
    "    # Reshape it back to a matrix\n",
    "    plt.imshow(mean_img)\n",
    "\n",
    "    plt.title(f'Average {title}')\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return mean_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4xRQfUOMtm"
   },
   "source": [
    "<b> Mean image for parasitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlgCf1-x2gli"
   },
   "outputs": [],
   "source": [
    "# If the label = 1 then the image is parasitised and if the label = 0 then the image is uninfected\n",
    "parasitized_data = []  # Create a list to store the parasitized data\n",
    "\n",
    "for img, label in zip(train_images, train_labels):\n",
    "\n",
    "        if label == 1:\n",
    "              \n",
    "              parasitized_data.append([img])          \n",
    "\n",
    "parasitized_mean = find_mean_img(np.array(parasitized_data), 'Parasitized')   # find the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkRt1rYIKE24"
   },
   "source": [
    "<b> Mean image for uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ji4w0okiIv6o"
   },
   "outputs": [],
   "source": [
    "# Similarly write the code to find the mean image of uninfected\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp9NP8yqPA69"
   },
   "source": [
    "####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzBagGEzHMHB"
   },
   "source": [
    "### <b>Converting RGB to HSV of Images using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJFCdE77H1Sg"
   },
   "source": [
    "###<b> Converting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32iwgGz7Iv-E"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "gfx=[]   # to hold the HSV image array\n",
    "\n",
    "for i in np.arange(0, 100, 1):\n",
    "\n",
    "  a = cv2.cvtColor(train_images[i], cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "  gfx.append(a)\n",
    "\n",
    "gfx = np.array(gfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3mr2iWd2pMK"
   },
   "outputs": [],
   "source": [
    "viewimage = np.random.randint(1, 100, 5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize = (18, 18))\n",
    "\n",
    "for t, i in zip(range(5), viewimage):\n",
    "\n",
    "  Title = train_labels[i]\n",
    "\n",
    "  ax[t].set_title(Title)\n",
    "\n",
    "  ax[t].imshow(gfx[i])\n",
    "\n",
    "  ax[t].set_axis_off()\n",
    "  \n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9a7cFllH794"
   },
   "source": [
    "###<b> Converting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-kUOULrGpBA"
   },
   "outputs": [],
   "source": [
    "# Similarly you can visualize for the images in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq4_3hv6J3ad"
   },
   "source": [
    "####<b>Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7x9uDxuJur7"
   },
   "source": [
    "###<b> Processing Images using Gaussian Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgkB_-J2KhBQ"
   },
   "source": [
    "###<b> Gaussian Blurring on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7GtZThUI6ug"
   },
   "outputs": [],
   "source": [
    "gbx = []  # To hold the blurred images\n",
    "\n",
    "for i in np.arange(0, 100, 1):\n",
    "\n",
    "  b = cv2.GaussianBlur(train_images[i], (5, 5), 0)\n",
    "\n",
    "  gbx.append(b)\n",
    "\n",
    "gbx = np.array(gbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9qa58ep207S"
   },
   "outputs": [],
   "source": [
    "viewimage = np.random.randint(1, 100, 5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize = (18, 18))\n",
    "\n",
    "for t, i in zip(range(5), viewimage):\n",
    "\n",
    "  Title = train_labels[i]\n",
    "\n",
    "  ax[t].set_title(Title)\n",
    "\n",
    "  \n",
    "  ax[t].imshow(gbx[i])\n",
    "  \n",
    "  ax[t].set_axis_off()\n",
    "  \n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTsJkRtCKlYZ"
   },
   "source": [
    "###<b> Gaussian Blurring on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbmMGySOKblh"
   },
   "outputs": [],
   "source": [
    "# Similarly you can apply Gaussian blurring for the images in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkpR8tQFKplr"
   },
   "source": [
    "####**Observations and insights: _____**\n",
    "\n",
    "**Think About It:** Would blurring help us for this problem statement in any way? What else can we try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtayck2-Pm3G"
   },
   "source": [
    "###<B>One Hot Encoding on the train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDWl6dVtOMom"
   },
   "outputs": [],
   "source": [
    "# Encoding Train Labels\n",
    "train_labels = to_categorical(____, 2)\n",
    "\n",
    "# Similarly let us try to encode test labels\n",
    "test_labels = to_categorical(_____, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4_ZzqDp8T5w"
   },
   "source": [
    "### **Base Model**\n",
    "\n",
    "**Note:** The Base Model has been fully built and evaluated with all outputs shown to give an idea about the process of the creation and evaluation of the performance of a CNN architecture. A similar process can be followed in iterating to build better-performing CNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTMSr0Xw6x3b"
   },
   "source": [
    "###<b> Importing the required libraries for building and training our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8eWxdyDp_ZC"
   },
   "outputs": [],
   "source": [
    "# Clearing backend\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout  \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "backend.clear_session()\n",
    "\n",
    "# Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
    "np.random.seed(42)\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwb4h0h64Km"
   },
   "source": [
    "###<b> Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LV1Ad_b4_LK"
   },
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\", input_shape = (64, 64, 3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation = \"softmax\")) # 2 represents output layer neurons \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sh0OGP268Qm"
   },
   "source": [
    "###<b> Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGGRMByKOMyG"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Dt8lFvz6_K6"
   },
   "source": [
    "<b> Using Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPwUYX3KOM34"
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
    "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91af114l7DCt"
   },
   "source": [
    "<b> Fit and train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XysPQsWn5EGq"
   },
   "outputs": [],
   "source": [
    "# Fit the model with min batch size as 32 can tune batch size to some factor of 2^power ] \n",
    "history = model.fit(train_images, train_labels, batch_size = 32, callbacks = callbacks, validation_split = 0.2, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn7bDXku7Ib8"
   },
   "source": [
    "###<b> Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHbgBrZe5Hqh"
   },
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_images, test_labels, verbose = 1)\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSoNNG_T7PkT"
   },
   "source": [
    "<b> Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwY1yx095NN5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(test_images)\n",
    "\n",
    "pred = np.argmax(pred, axis = 1) \n",
    "\n",
    "y_true = np.argmax(test_labels, axis = 1)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_true, pred))\n",
    "\n",
    "# Plotting the heatmap using confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['Uninfected', 'Parasitized'], yticklabels = ['Uninfected', 'Parasitized'])\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWq4jyPL7f5a"
   },
   "source": [
    "<b>Plotting the train and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3h5gAwyW05u"
   },
   "outputs": [],
   "source": [
    "# Function to plot train and validation accuracy \n",
    "def plot_accuracy(history):\n",
    "\n",
    "    N = len(history.history[\"accuracy\"])\n",
    "\n",
    "    plt.figure(figsize = (7, 7))\n",
    "\n",
    "    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label = \"train_accuracy\", ls = '--')\n",
    "\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label = \"val_accuracy\", ls = '--')\n",
    "\n",
    "    plt.title(\"Accuracy vs Epoch\")\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    \n",
    "    plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnxxiR-T5PsQ"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGOtxZ10fEIn"
   },
   "source": [
    "\n",
    "\n",
    "* Here we can clearly observe that the training and valiation accuracy are increasing \n",
    "* And we can also notice that validation accuracy is slightly higher than the train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCDgxiFnXSek"
   },
   "source": [
    "So now let's try to build another model with few more add on layers and try to check if we can try to improve the model. Therefore try to build a model by adding few layers if required and altering the activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tJeklwR77rs"
   },
   "source": [
    "###<b> Model 1\n",
    "####<b> Trying to improve the performance of our model by adding new layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-NnG6Rp9_w7"
   },
   "outputs": [],
   "source": [
    "backend.clear_session() # Clearing the backend for new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT99NdnzZW3n"
   },
   "source": [
    "###<b> Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TaSet9DONGV"
   },
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model1 = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the model here and add new layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6cTCOAVZZpI"
   },
   "source": [
    "###<b> Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWcQhKidONIr"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss = __________, optimizer = _______, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PSskadUZhUt"
   },
   "source": [
    "<b> Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4_T2_sKONMA"
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
    "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYLgQK9DZkoc"
   },
   "source": [
    "<b>Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7S7LmVTZjrd"
   },
   "outputs": [],
   "source": [
    "history1 = model1.fit(_____________, __________, batch_size = ______, callbacks = callbacks,  validation_split = ______, epochs = ______, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHABkGRzZwyt"
   },
   "source": [
    "###<b> Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yie1Z-R6Zjt_"
   },
   "outputs": [],
   "source": [
    "accuracy1 = model1.evaluate(_________, _____________, verbose = 1)\n",
    "\n",
    "print('\\n', 'Test_Accuracy:-', accuracy1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCJEZ6cqZywk"
   },
   "source": [
    "<b> Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmuJFfUjZjws"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roDugWeKaVDW"
   },
   "source": [
    "<b> Plotting the train and the validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JakeVNnbZjzh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsx7jVjaiO9V"
   },
   "source": [
    "###<b>Think about it:</b><br>\n",
    "Now let's build a model with LeakyRelu as the activation function  \n",
    "\n",
    "*  Can the model performance be improved if we change our activation function to LeakyRelu?\n",
    "*  Can BatchNormalization improve our model?\n",
    "\n",
    "Let us try to build a model using BatchNormalization and using LeakyRelu as our activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU4qr7amiXds"
   },
   "source": [
    "###<b> Model 2 with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOXd_ciyZj2n"
   },
   "outputs": [],
   "source": [
    "backend.clear_session() # Clearing the backend for new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kDMUu-U8vV3"
   },
   "source": [
    "###<b> Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJBcwhtbiu0l"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), padding = 'same'))\n",
    "\n",
    "'''\n",
    "\n",
    "Complete this model using BatchNormalization layers and by using LeakyRelu as the activation function\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9WQ7-cOLIQy"
   },
   "source": [
    "###<b>Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SiRoyZ7LHSL"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOVzX0WTDUEy"
   },
   "source": [
    "<b> Using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC0FcITongxx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "create the callbacks similarly as done in the base model\n",
    "As callbacks will help us in saving our checkpoints and stopping at an accuracy where the model doesnot seem to improve\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxj3AcS0Dqm8"
   },
   "source": [
    "<b>Fit and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMy-4IGajL31"
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(train_images, train_labels, batch_size = 32, callbacks = callbacks, validation_split = 0.2, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9DkuwVYDtc3"
   },
   "source": [
    "<b>Plotting the train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILu-oHB_jxGY"
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSREnGkgDz6N"
   },
   "source": [
    "###<b>Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZGH8gE089Gx"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model to calculate the accuracy\n",
    "\n",
    "accuracy = model2.evaluate(________, ______________, verbose = 1)\n",
    "\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiIQnwKaJ27O"
   },
   "source": [
    "####<b>Observations and insights: ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDL1BQZ7_JxS"
   },
   "source": [
    "<b> Generate the classification report and confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB-CYdwC9V8P"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model2.predict(_______)\n",
    "\n",
    "pred = np.argmax(pred, axis = 1) \n",
    "\n",
    "y_true = np.argmax(________________, axis = 1)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(______, _______))\n",
    "\n",
    "# Plotting the heatmap using confusion matrix\n",
    "\n",
    "cm = confusion_matrix(_____, _____)\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['Uninfected', 'Parasitized'], yticklabels = ['Uninfected', 'Parasitized'])\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUwBBVzuijlU"
   },
   "source": [
    "###**Think About It :**<br>\n",
    "\n",
    "* Can we improve the model with Image Data Augmentation?\n",
    "* References to image data augmentation can be seen below:\n",
    "  *   [Image Augmentation for Computer Vision](https://www.mygreatlearning.com/blog/understanding-data-augmentation/)\n",
    "  *   [How to Configure Image Data Augmentation in Keras?](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYVJZ0Psi0D0"
   },
   "source": [
    "###<b>Model 3 with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ddfrhcLihpz"
   },
   "outputs": [],
   "source": [
    "backend.clear_session() # Clearing backend for new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqOnCq3FZ6JG"
   },
   "source": [
    "###<b> Using image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnvWygv4aAZc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Using ImageDataGenerator to generate images\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True, \n",
    "                                  zoom_range = 0.5, rotation_range = 30)\n",
    "\n",
    "val_datagen  = ImageDataGenerator()\n",
    "\n",
    "# Flowing training images using train_datagen generator\n",
    "train_generator = train_datagen.flow(x = _______, y = __________, batch_size = 64, seed = 42, shuffle = True)\n",
    "\n",
    "\n",
    "# Flowing validation images using val_datagen generator\n",
    "val_generator =  val_datagen.flow(x = _________, y = _________, batch_size = 64, seed = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2cJN07Bbofx"
   },
   "source": [
    "###**Think About It :**<br>\n",
    "\n",
    "*  Check if the performance of the model can be improved by changing different parameters in the ImageDataGenerator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "341Ilg5McowX"
   },
   "source": [
    "####<B>Visualizing Augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ws3BE91RbFBy"
   },
   "outputs": [],
   "source": [
    "# Creating an iterable for images and labels from the training data\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Plotting 16 images from the training data\n",
    "fig, axes = plt.subplots(4, 4, figsize = (16, 8))\n",
    "\n",
    "fig.set_size_inches(16, 16)\n",
    "for (image, label, ax) in zip(images, labels, axes.flatten()):\n",
    "\n",
    "    ax.imshow(image)\n",
    "\n",
    "    if label[1] == 1: \n",
    "\n",
    "        ax.set_title('parasitized')\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.set_title('uninfected')\n",
    "\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfCMCaAZdK3o"
   },
   "source": [
    "####<b>Observations and insights: ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrpS4Azamjs4"
   },
   "source": [
    "###<b>Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVELJI8uihsz"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "# Build the model here\n",
    "# Use this as the optimizer\n",
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model3.compile(loss = ________________, optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-HrtTMJnEPl"
   },
   "source": [
    "<b>Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMWPxLvdihvf"
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
    "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEeOIRrCnMBh"
   },
   "source": [
    "<b> Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_2dSGYMihyk"
   },
   "outputs": [],
   "source": [
    "history3 = model3.fit(train_generator, \n",
    "                                  validation_data = val_generator,\n",
    "                                  batch_size = _____, callbacks = ___________,\n",
    "                                  epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EFWVEUKoM1U"
   },
   "source": [
    "###<B>Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8twGIoxWnrCb"
   },
   "source": [
    "<b>Plot the train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjB4IecBih2K"
   },
   "outputs": [],
   "source": [
    "# Potting the accuracies\n",
    "plot_accuracy(_________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9sBTSvL_Uz-"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on test data\n",
    "accuracy3 = _________.evaluate(________, ___________, verbose = 1)\n",
    "\n",
    "print('\\n', 'Test_Accuracy:-', accuracy3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_VDQxXwoe6u"
   },
   "source": [
    "<B>Plotting the classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxdOpuzJoj8l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obzJSEF5ypj-"
   },
   "source": [
    "<b> Now, let us try to use a pretrained model like VGG16 and check how it performs on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra-GUCjbLHGg"
   },
   "source": [
    "### **Pre-trained model (VGG16)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dH2_XWNLyac"
   },
   "outputs": [],
   "source": [
    "# Clearing backend\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "backend.clear_session()\n",
    "\n",
    "# Fixing the seed for random number generators\n",
    "np.random.seed(42)\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCtAgs1FAxhp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "vgg = VGG16(include_top = _________, weights = 'imagenet', input_shape = (64, 64, 3))\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDQ7RswtA0jf"
   },
   "outputs": [],
   "source": [
    "transfer_layer = vgg.get_layer('block5_pool')\n",
    "\n",
    "vgg.trainable = False\n",
    "\n",
    "# Add classification layers on top of it  \n",
    "x = Flatten()(transfer_layer.output)  # Flatten the output from the 3rd block of the VGG16 model\n",
    "\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "# Similarly add a dense layer with 128 neurons\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Add a dense layer with 64 neurons\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "pred = Dense(______, activation = 'softmax')(_____)\n",
    "\n",
    "model4 = Model(vgg.input, pred) # Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhoug92KFWPa"
   },
   "source": [
    "###<b>Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdJ8C0L5Lkyt"
   },
   "outputs": [],
   "source": [
    "# Compiling the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBPzjtxcFLQt"
   },
   "source": [
    "<b> using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS3skmQBR4if"
   },
   "outputs": [],
   "source": [
    "# Adding Callbacks to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_ZeobGmFIOF"
   },
   "source": [
    "<b>Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6sSx39uL1mS"
   },
   "outputs": [],
   "source": [
    "# Fitting the model and running the model for 10 epochs\n",
    "history4 = model4.fit(\n",
    "            __________, ______________,\n",
    "            epochs = _________,\n",
    "            callbacks = _____________,\n",
    "            batch_size = _________,\n",
    "            validation_split = 0.2,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0WI9dvDFBaR"
   },
   "source": [
    "<b>Plot the train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKmS2XyiMBqb"
   },
   "outputs": [],
   "source": [
    "# plotting the accuracies\n",
    "plot_accuracy(__________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb3jUduI0BNs"
   },
   "source": [
    "###**Observations and insights: _____**\n",
    "\n",
    "*   What can be observed from the validation and train curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykl7xLODEoix"
   },
   "source": [
    "###<b> Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxcgkSoivwWf"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_lr-dUHE77F"
   },
   "source": [
    "<b>Plotting the classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jns2wf2HMBto"
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix and generate a classification report for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEZPA_mN0tUo"
   },
   "source": [
    "###<b>Think about it:</b>\n",
    "*  What observations and insights can be drawn from the confusion matrix and classification report?\n",
    "*  Choose the model with the best accuracy scores from all the above models and save it as a final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Smzi8y5AEYIi"
   },
   "source": [
    "####<b> Observations and Conclusions drawn from the final model: _____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo6IpgOZ1n-g"
   },
   "source": [
    "**Improvements that can be done:**<br>\n",
    "\n",
    "\n",
    "*  Can the model performance be improved using other pre-trained models or different CNN architecture?\n",
    "*  You can try to build a model using these HSV images and compare them with your other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJB6yf2EczFk"
   },
   "source": [
    "#### **Insights**\n",
    "\n",
    "####**Refined insights**:\n",
    "- What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "####**Comparison of various techniques and their relative performance**:\n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "####**Proposal for the final solution design**:\n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "requirements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
